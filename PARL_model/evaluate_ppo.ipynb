{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expanded-passion",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "import lightsim2grid\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from lightsim2grid.LightSimBackend import LightSimBackend\n",
    "import numpy as np\n",
    "from agent import Track2PowerNetAgent\n",
    "\n",
    "from d3qn.adversary import D3QN_Opponent\n",
    "from l2rpn_baselines.DoubleDuelingDQN.DoubleDuelingDQNConfig import DoubleDuelingDQNConfig as cfg\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from ppo.ppo import PPO\n",
    "from ppo.nnpytorch import FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "differential-angle",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIMESTEP = 7 * 288\n",
    "\n",
    "LINES = ['0_1_0', '0_2_1', '10_11_2', '69_70_3', '23_71_4', '70_71_5',\n",
    "       '70_72_6', '69_73_7', '69_74_8', '68_74_9', '73_74_10', '75_76_11',\n",
    "       '68_76_12', '1_11_13', '74_76_14', '76_77_15', '77_78_16',\n",
    "       '76_79_17', '76_79_18', '78_79_19', '76_81_20', '81_82_21',\n",
    "       '82_83_22', '82_84_23', '2_11_24', '83_84_25', '84_85_26',\n",
    "       '84_87_27', '84_88_28', '87_88_29', '88_89_30', '88_89_31',\n",
    "       '89_90_32', '88_91_33', '88_91_34', '6_11_35', '90_91_36',\n",
    "       '91_92_37', '91_93_38', '92_93_39', '93_94_40', '79_95_41',\n",
    "       '81_95_42', '93_95_43', '79_96_44', '79_97_45', '10_12_46',\n",
    "       '79_98_47', '91_99_48', '93_99_49', '94_95_50', '95_96_51',\n",
    "       '97_99_52', '98_99_53', '99_100_54', '91_101_55', '100_101_56',\n",
    "       '11_13_57', '99_102_58', '99_103_59', '102_103_60', '102_104_61',\n",
    "       '99_105_62', '103_104_63', '104_105_64', '104_106_65',\n",
    "       '104_107_66', '105_106_67', '12_14_68', '107_108_69', '102_109_70',\n",
    "       '108_109_71', '109_110_72', '109_111_73', '16_112_74', '31_112_75',\n",
    "       '31_113_76', '26_114_77', '113_114_78', '13_14_79', '11_116_80',\n",
    "       '74_117_81', '75_117_82', '11_15_83', '14_16_84', '3_4_85',\n",
    "       '15_16_86', '16_17_87', '17_18_88', '18_19_89', '14_18_90',\n",
    "       '19_20_91', '20_21_92', '21_22_93', '22_23_94', '22_24_95',\n",
    "       '2_4_96', '24_26_97', '26_27_98', '27_28_99', '7_29_100',\n",
    "       '25_29_101', '16_30_102', '28_30_103', '22_31_104', '30_31_105',\n",
    "       '26_31_106', '4_5_107', '14_32_108', '18_33_109', '34_35_110',\n",
    "       '34_36_111', '32_36_112', '33_35_113', '33_36_114', '36_38_115',\n",
    "       '36_39_116', '29_37_117', '5_6_118', '38_39_119', '39_40_120',\n",
    "       '39_41_121', '40_41_122', '42_43_123', '33_42_124', '43_44_125',\n",
    "       '44_45_126', '45_46_127', '45_47_128', '7_8_129', '46_48_130',\n",
    "       '41_48_131', '41_48_132', '44_48_133', '47_48_134', '48_49_135',\n",
    "       '48_50_136', '50_51_137', '51_52_138', '52_53_139', '8_9_140',\n",
    "       '48_53_141', '48_53_142', '53_54_143', '53_55_144', '54_55_145',\n",
    "       '55_56_146', '49_56_147', '55_57_148', '50_57_149', '53_58_150',\n",
    "       '3_10_151', '55_58_152', '55_58_153', '54_58_154', '58_59_155',\n",
    "       '58_60_156', '59_60_157', '59_61_158', '60_61_159', '62_63_160',\n",
    "       '37_64_161', '4_10_162', '63_64_163', '48_65_164', '48_65_165',\n",
    "       '61_65_166', '61_66_167', '65_66_168', '46_68_169', '48_68_170',\n",
    "       '68_69_171', '23_69_172', '7_4_173', '25_24_174', '80_79_175',\n",
    "       '86_85_176', '115_67_177', '29_16_178', '37_36_179', '62_58_180',\n",
    "       '63_60_181', '64_65_182', '64_67_183', '67_68_184', '80_67_185']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "comic-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, env, agent, opponent):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.opponent = opponent\n",
    "        self.action_counter_arr = [] # count the actions taken for each episode\n",
    "\n",
    "    def run(self, opponent, num_episodes):\n",
    "        steps_buffer = []\n",
    "        rewards_buffer = []\n",
    "\n",
    "        for i_episode in range(num_episodes):\n",
    "            action_counter = {}\n",
    "            obs = self.env.reset()\n",
    "            \n",
    "            max_day = (\n",
    "                self.env.chronics_handler.max_timestep() - MAX_TIMESTEP) // 288\n",
    "            start_timestep = np.random.randint(\n",
    "                max_day) * 288 - 1  # start at 00:00\n",
    "            if start_timestep > 0:\n",
    "                print(f'episode {i_episode} starting at timestep {start_timestep}')\n",
    "                self.env.fast_forward_chronics(start_timestep)\n",
    "\n",
    "            obs = self.env.get_obs()\n",
    "            done = False\n",
    "            steps = 0\n",
    "            rewards = 0\n",
    "            \n",
    "            while not done:\n",
    "                action = self.agent.act(obs, None, None)\n",
    "                obs, reward, done, info = self.env.step(action)\n",
    "#                 assert not info['is_illegal'] and not info['is_ambiguous']\n",
    "                if (info['is_illegal'] or info['is_ambiguous']):\n",
    "                    if done:\n",
    "                        break\n",
    "                    continue\n",
    "                rewards += reward\n",
    "                steps += 1\n",
    "                \n",
    "                if done: # to prevent opponent from taking action on finished episode\n",
    "                    break\n",
    "                \n",
    "                if opponent:\n",
    "                    if opponent.remaining_time >= 0:\n",
    "                        obs.time_before_cooldown_line[opponent.attack_line] = opponent.remaining_time\n",
    "                        opponent.remaining_time -= 1\n",
    "                    else: # attack (only one disconnection at a time)\n",
    "                        response = opponent.act(obs, None, None)\n",
    "                        if response is not None:\n",
    "                            attack, a = response\n",
    "                            if a not in action_counter:\n",
    "                                action_counter[a] = 0\n",
    "                            action_counter[a] += 1\n",
    "                            obs, opp_reward, done, info = env.step(attack)\n",
    "                \n",
    "                if steps >= MAX_TIMESTEP:\n",
    "                    break\n",
    "            self.action_counter_arr.append(action_counter)\n",
    "            steps_buffer.append(steps)\n",
    "            rewards_buffer.append(rewards)\n",
    "            print(f'Episode {i_episode+1}/{num_episodes} - Reward: {rewards:.2f}, Num Steps: {steps}')\n",
    "\n",
    "        return np.mean(steps_buffer), np.mean(rewards_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-clock",
   "metadata": {},
   "source": [
    "## Untrained PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "shared-devon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05-29 13:04:30 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n",
      "\u001b[32m[05-29 13:04:30 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n",
      "episode 0 starting at timestep 4895\n",
      "Episode 1/20 - Reward: 124555.07, Num Steps: 155\n",
      "episode 1 starting at timestep 5183\n",
      "Episode 2/20 - Reward: 111512.83, Num Steps: 130\n",
      "episode 2 starting at timestep 4031\n",
      "Episode 3/20 - Reward: 38061.56, Num Steps: 33\n",
      "episode 3 starting at timestep 1727\n",
      "Episode 4/20 - Reward: 10048.92, Num Steps: 9\n",
      "episode 4 starting at timestep 1151\n",
      "Episode 5/20 - Reward: 112424.78, Num Steps: 143\n",
      "episode 5 starting at timestep 5183\n",
      "Episode 6/20 - Reward: 52922.99, Num Steps: 60\n",
      "episode 6 starting at timestep 2303\n",
      "Episode 7/20 - Reward: 132299.66, Num Steps: 139\n",
      "episode 7 starting at timestep 1727\n",
      "Episode 8/20 - Reward: 36447.99, Num Steps: 32\n",
      "episode 8 starting at timestep 3743\n",
      "Episode 9/20 - Reward: 33477.28, Num Steps: 28\n",
      "episode 9 starting at timestep 2015\n",
      "Episode 10/20 - Reward: 36186.67, Num Steps: 39\n",
      "episode 10 starting at timestep 2879\n",
      "Episode 11/20 - Reward: 68809.59, Num Steps: 78\n",
      "Episode 12/20 - Reward: 254139.94, Num Steps: 228\n",
      "episode 12 starting at timestep 1151\n",
      "Episode 13/20 - Reward: 5959.31, Num Steps: 6\n",
      "episode 13 starting at timestep 863\n",
      "Episode 14/20 - Reward: 35565.90, Num Steps: 30\n",
      "episode 14 starting at timestep 1439\n",
      "Episode 15/20 - Reward: 84287.61, Num Steps: 108\n",
      "episode 15 starting at timestep 5471\n",
      "Episode 16/20 - Reward: 60100.86, Num Steps: 72\n",
      "episode 16 starting at timestep 287\n",
      "Episode 17/20 - Reward: 15350.50, Num Steps: 14\n",
      "episode 17 starting at timestep 4895\n",
      "Episode 18/20 - Reward: 70232.39, Num Steps: 70\n",
      "episode 18 starting at timestep 863\n",
      "Episode 19/20 - Reward: 67333.55, Num Steps: 57\n",
      "episode 19 starting at timestep 5183\n",
      "Episode 20/20 - Reward: 65934.92, Num Steps: 87\n",
      "num_episodes: 20, mean_reward: 70782.6, mean_steps: 75.9\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 20\n",
    "# how frequent the attack is.\n",
    "# after each attack, next_attack_time is set to 1 + rnadint(attack_period\n",
    "attack_period = 50\n",
    "# how long the line is cooled down for after attack\n",
    "attack_duration = 20\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "backend = LightSimBackend()\n",
    "env = grid2op.make(\"l2rpn_neurips_2020_track2_small\", backend=backend)\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "# state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_mean = torch.zeros((1, 3868))\n",
    "state_std = torch.ones((1, 3868))\n",
    "\n",
    "# opponent hyperparameters\n",
    "hyperparameters = {\n",
    "    'timesteps_per_batch': 2048, \n",
    "    'max_timesteps_per_episode': 200, \n",
    "    'gamma': 0.99, \n",
    "    'n_updates_per_iteration': 10,\n",
    "    'lr': 3e-4, \n",
    "    'clip': 0.2,\n",
    "    'lines_attacked': LINES,\n",
    "    'attack_duration': 1,\n",
    "    'danger': 0.9,\n",
    "    'state_dim': 3198\n",
    "}\n",
    "\n",
    "agent = Track2PowerNetAgent(env.action_space)\n",
    "\n",
    "opponent = PPO(env=env, agent=agent, policy_class=FFN, state_mean=state_mean, state_std=state_std, **hyperparameters)\n",
    "\n",
    "evaluator = Evaluator(env, agent, opponent)\n",
    "\n",
    "mean_steps, mean_rewards = evaluator.run(opponent, num_episodes)\n",
    "print('num_episodes: {}, mean_reward: {:.1f}, mean_steps: {:.1f}'.format(\n",
    "    num_episodes, mean_rewards, mean_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "crucial-waterproof",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{84: 11,\n",
       "  82: 3,\n",
       "  22: 4,\n",
       "  143: 2,\n",
       "  158: 4,\n",
       "  16: 1,\n",
       "  64: 1,\n",
       "  33: 3,\n",
       "  66: 1,\n",
       "  175: 1,\n",
       "  180: 2,\n",
       "  127: 1,\n",
       "  12: 3,\n",
       "  184: 1,\n",
       "  41: 1,\n",
       "  54: 1,\n",
       "  151: 1,\n",
       "  168: 1,\n",
       "  160: 1,\n",
       "  55: 1,\n",
       "  89: 1,\n",
       "  31: 1,\n",
       "  29: 1,\n",
       "  142: 1,\n",
       "  108: 1,\n",
       "  59: 1,\n",
       "  44: 1},\n",
       " {143: 4,\n",
       "  89: 1,\n",
       "  78: 2,\n",
       "  33: 1,\n",
       "  92: 1,\n",
       "  184: 1,\n",
       "  148: 1,\n",
       "  41: 1,\n",
       "  16: 6,\n",
       "  23: 1,\n",
       "  82: 3,\n",
       "  158: 2,\n",
       "  168: 2,\n",
       "  44: 1,\n",
       "  84: 2,\n",
       "  136: 1,\n",
       "  123: 1,\n",
       "  49: 1,\n",
       "  142: 1,\n",
       "  182: 1,\n",
       "  22: 1,\n",
       "  97: 1,\n",
       "  14: 1,\n",
       "  128: 1,\n",
       "  3: 1,\n",
       "  151: 1,\n",
       "  12: 2,\n",
       "  43: 1,\n",
       "  140: 1},\n",
       " {84: 2, 37: 1, 143: 1, 104: 1, 175: 1, 82: 1, 12: 1, 29: 1, 16: 1, 26: 1},\n",
       " {92: 1, 82: 1, 26: 1},\n",
       " {82: 2,\n",
       "  66: 2,\n",
       "  160: 3,\n",
       "  94: 1,\n",
       "  135: 1,\n",
       "  22: 2,\n",
       "  78: 1,\n",
       "  64: 1,\n",
       "  12: 3,\n",
       "  143: 2,\n",
       "  142: 1,\n",
       "  113: 2,\n",
       "  44: 1,\n",
       "  97: 1,\n",
       "  148: 1,\n",
       "  84: 8,\n",
       "  29: 1,\n",
       "  16: 3,\n",
       "  128: 1,\n",
       "  89: 2,\n",
       "  158: 1,\n",
       "  175: 1,\n",
       "  55: 1,\n",
       "  184: 1,\n",
       "  37: 1,\n",
       "  33: 2,\n",
       "  70: 1},\n",
       " {84: 2,\n",
       "  89: 2,\n",
       "  107: 1,\n",
       "  64: 2,\n",
       "  158: 2,\n",
       "  160: 1,\n",
       "  66: 1,\n",
       "  116: 1,\n",
       "  77: 1,\n",
       "  5: 1,\n",
       "  35: 1,\n",
       "  14: 1,\n",
       "  33: 1,\n",
       "  82: 1,\n",
       "  168: 1,\n",
       "  173: 1},\n",
       " {29: 1,\n",
       "  126: 1,\n",
       "  89: 1,\n",
       "  143: 3,\n",
       "  108: 3,\n",
       "  33: 1,\n",
       "  62: 1,\n",
       "  45: 4,\n",
       "  158: 1,\n",
       "  19: 1,\n",
       "  12: 2,\n",
       "  147: 1,\n",
       "  128: 2,\n",
       "  84: 3,\n",
       "  160: 1,\n",
       "  94: 1,\n",
       "  38: 1,\n",
       "  22: 1,\n",
       "  123: 1,\n",
       "  82: 5,\n",
       "  50: 1,\n",
       "  16: 1,\n",
       "  151: 1,\n",
       "  78: 1,\n",
       "  53: 2,\n",
       "  167: 1,\n",
       "  107: 1,\n",
       "  86: 1,\n",
       "  180: 1,\n",
       "  64: 1,\n",
       "  177: 1},\n",
       " {160: 1, 12: 2, 127: 1, 71: 1, 78: 2, 33: 1, 22: 1, 180: 1},\n",
       " {8: 1, 94: 1, 158: 2, 142: 1, 108: 1, 185: 1, 172: 1, 143: 1, 26: 1},\n",
       " {144: 1,\n",
       "  22: 2,\n",
       "  156: 1,\n",
       "  171: 1,\n",
       "  84: 1,\n",
       "  158: 1,\n",
       "  115: 1,\n",
       "  123: 2,\n",
       "  89: 1,\n",
       "  45: 1,\n",
       "  26: 1},\n",
       " {89: 1,\n",
       "  84: 4,\n",
       "  14: 1,\n",
       "  130: 1,\n",
       "  142: 1,\n",
       "  181: 1,\n",
       "  94: 3,\n",
       "  59: 1,\n",
       "  45: 1,\n",
       "  143: 2,\n",
       "  175: 1,\n",
       "  41: 1,\n",
       "  82: 2,\n",
       "  117: 1,\n",
       "  70: 1,\n",
       "  128: 1,\n",
       "  5: 1,\n",
       "  16: 1,\n",
       "  26: 1},\n",
       " {29: 2,\n",
       "  84: 19,\n",
       "  82: 3,\n",
       "  16: 4,\n",
       "  78: 5,\n",
       "  166: 1,\n",
       "  38: 1,\n",
       "  158: 3,\n",
       "  125: 1,\n",
       "  182: 2,\n",
       "  41: 2,\n",
       "  48: 1,\n",
       "  12: 2,\n",
       "  5: 3,\n",
       "  160: 1,\n",
       "  22: 2,\n",
       "  183: 1,\n",
       "  128: 3,\n",
       "  131: 1,\n",
       "  180: 2,\n",
       "  161: 1,\n",
       "  168: 1,\n",
       "  33: 3,\n",
       "  132: 1,\n",
       "  64: 1,\n",
       "  143: 5,\n",
       "  71: 1,\n",
       "  44: 1,\n",
       "  107: 1,\n",
       "  62: 1,\n",
       "  177: 1},\n",
       " {14: 1, 80: 1},\n",
       " {94: 1, 12: 2, 44: 1, 84: 1, 158: 1, 78: 1, 92: 1, 5: 1, 72: 1},\n",
       " {8: 1,\n",
       "  84: 10,\n",
       "  168: 1,\n",
       "  22: 1,\n",
       "  12: 1,\n",
       "  94: 1,\n",
       "  50: 1,\n",
       "  158: 2,\n",
       "  97: 2,\n",
       "  16: 2,\n",
       "  7: 1,\n",
       "  33: 2,\n",
       "  160: 1,\n",
       "  180: 1,\n",
       "  20: 1,\n",
       "  82: 1,\n",
       "  184: 1,\n",
       "  24: 1,\n",
       "  166: 1,\n",
       "  143: 2,\n",
       "  183: 1,\n",
       "  26: 1},\n",
       " {74: 1,\n",
       "  84: 10,\n",
       "  118: 1,\n",
       "  12: 1,\n",
       "  158: 1,\n",
       "  82: 1,\n",
       "  33: 1,\n",
       "  185: 1,\n",
       "  143: 1,\n",
       "  180: 1,\n",
       "  128: 2,\n",
       "  123: 1,\n",
       "  8: 1,\n",
       "  73: 1},\n",
       " {16: 1, 84: 2, 173: 1},\n",
       " {143: 2,\n",
       "  158: 2,\n",
       "  89: 1,\n",
       "  45: 1,\n",
       "  85: 1,\n",
       "  185: 1,\n",
       "  16: 3,\n",
       "  41: 1,\n",
       "  12: 1,\n",
       "  29: 1,\n",
       "  94: 1,\n",
       "  50: 1,\n",
       "  84: 1,\n",
       "  82: 1,\n",
       "  33: 2,\n",
       "  108: 1,\n",
       "  168: 1,\n",
       "  132: 1,\n",
       "  73: 1},\n",
       " {14: 1,\n",
       "  33: 2,\n",
       "  53: 1,\n",
       "  16: 2,\n",
       "  128: 1,\n",
       "  41: 1,\n",
       "  22: 1,\n",
       "  84: 3,\n",
       "  143: 1,\n",
       "  93: 2,\n",
       "  86: 1,\n",
       "  120: 1,\n",
       "  108: 1,\n",
       "  26: 1},\n",
       " {78: 2,\n",
       "  84: 7,\n",
       "  22: 1,\n",
       "  33: 4,\n",
       "  143: 1,\n",
       "  158: 1,\n",
       "  4: 1,\n",
       "  37: 1,\n",
       "  82: 3,\n",
       "  7: 1,\n",
       "  130: 1,\n",
       "  70: 1,\n",
       "  12: 1,\n",
       "  167: 1,\n",
       "  135: 1,\n",
       "  29: 1,\n",
       "  26: 1}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.action_counter_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-gilbert",
   "metadata": {},
   "source": [
    "## Trained PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acquired-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05-29 22:32:53 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n",
      "\u001b[32m[05-29 22:32:53 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n",
      "Episode 1/20 - Reward: 1785.14, Num Steps: 2\n",
      "episode 1 starting at timestep 3167\n",
      "Episode 2/20 - Reward: 2613.94, Num Steps: 3\n",
      "episode 2 starting at timestep 575\n",
      "Episode 3/20 - Reward: 4962.91, Num Steps: 5\n",
      "episode 3 starting at timestep 863\n",
      "Episode 4/20 - Reward: 4323.29, Num Steps: 4\n",
      "episode 4 starting at timestep 2303\n",
      "Episode 5/20 - Reward: 4086.73, Num Steps: 5\n",
      "episode 5 starting at timestep 3455\n",
      "Episode 6/20 - Reward: 2381.18, Num Steps: 3\n",
      "episode 6 starting at timestep 4319\n",
      "Episode 7/20 - Reward: 2916.08, Num Steps: 3\n",
      "episode 7 starting at timestep 1151\n",
      "Episode 8/20 - Reward: 969.61, Num Steps: 1\n",
      "episode 8 starting at timestep 5471\n",
      "Episode 9/20 - Reward: 4825.74, Num Steps: 5\n",
      "episode 9 starting at timestep 1439\n",
      "Episode 10/20 - Reward: 750.15, Num Steps: 1\n",
      "episode 10 starting at timestep 5471\n",
      "Episode 11/20 - Reward: 6200.95, Num Steps: 8\n",
      "episode 11 starting at timestep 5471\n",
      "Episode 12/20 - Reward: 2495.72, Num Steps: 3\n",
      "episode 12 starting at timestep 1151\n",
      "Episode 13/20 - Reward: 2948.81, Num Steps: 3\n",
      "episode 13 starting at timestep 2015\n",
      "Episode 14/20 - Reward: 1068.55, Num Steps: 1\n",
      "episode 14 starting at timestep 4031\n",
      "Episode 15/20 - Reward: 3835.34, Num Steps: 5\n",
      "episode 15 starting at timestep 5183\n",
      "Episode 16/20 - Reward: 3293.08, Num Steps: 4\n",
      "episode 16 starting at timestep 1439\n",
      "Episode 17/20 - Reward: 4566.88, Num Steps: 5\n",
      "episode 17 starting at timestep 2591\n",
      "Episode 18/20 - Reward: 990.76, Num Steps: 1\n",
      "episode 18 starting at timestep 4319\n",
      "Episode 19/20 - Reward: 3237.71, Num Steps: 3\n",
      "episode 19 starting at timestep 1727\n",
      "Episode 20/20 - Reward: 3953.24, Num Steps: 5\n",
      "num_episodes: 20, mean_reward: 3110.3, mean_steps: 3.5\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 20\n",
    "# how frequent the attack is.\n",
    "# after each attack, next_attack_time is set to 1 + rnadint(attack_period\n",
    "attack_period = 50\n",
    "# how long the line is cooled down for after attack\n",
    "attack_duration = 20\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "backend = LightSimBackend()\n",
    "env = grid2op.make(\"l2rpn_neurips_2020_track2_small\", backend=backend)\n",
    "warnings.filterwarnings(\"default\")\n",
    "\n",
    "# state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "# state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_mean = torch.zeros((1, 3868))\n",
    "state_std = torch.ones((1, 3868))\n",
    "\n",
    "# opponent hyperparameters\n",
    "hyperparameters = {\n",
    "    'timesteps_per_batch': 2048, \n",
    "    'max_timesteps_per_episode': 200, \n",
    "    'gamma': 0.99, \n",
    "    'n_updates_per_iteration': 10,\n",
    "    'lr': 3e-4, \n",
    "    'clip': 0.2,\n",
    "    'lines_attacked': LINES,\n",
    "    'attack_duration': 1,\n",
    "    'danger': 0.9,\n",
    "    'state_dim': 3198\n",
    "}\n",
    "\n",
    "agent = Track2PowerNetAgent(env.action_space)\n",
    "\n",
    "opponent = PPO(env=env, agent=agent, policy_class=FFN, state_mean=state_mean, state_std=state_std, **hyperparameters)\n",
    "opponent.actor.load_state_dict(torch.load('./ppo_actor.pth'))\n",
    "\n",
    "evaluator = Evaluator(env, agent, opponent)\n",
    "\n",
    "mean_steps, mean_rewards = evaluator.run(opponent, num_episodes)\n",
    "print('num_episodes: {}, mean_reward: {:.1f}, mean_steps: {:.1f}'.format(\n",
    "    num_episodes, mean_rewards, mean_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "running-gender",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{177: 1},\n",
       " {140: 1},\n",
       " {15: 1},\n",
       " {163: 1, 176: 1},\n",
       " {15: 1},\n",
       " {174: 1},\n",
       " {15: 1},\n",
       " {176: 1},\n",
       " {101: 1},\n",
       " {176: 1},\n",
       " {107: 1, 174: 1},\n",
       " {101: 1},\n",
       " {15: 1},\n",
       " {177: 1},\n",
       " {101: 1},\n",
       " {160: 1, 140: 1},\n",
       " {101: 1},\n",
       " {176: 1},\n",
       " {176: 1},\n",
       " {163: 1}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.action_counter_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-chassis",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
