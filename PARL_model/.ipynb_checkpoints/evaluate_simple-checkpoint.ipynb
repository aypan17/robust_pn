{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "proud-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "import lightsim2grid\n",
    "import warnings\n",
    "\n",
    "from lightsim2grid.LightSimBackend import LightSimBackend\n",
    "import numpy as np\n",
    "from agent import Track2PowerNetAgent\n",
    "\n",
    "from simple_opponents.random_opponent import RandomOpponent\n",
    "from simple_opponents.nothing_opponent import DoNothingOpponent\n",
    "\n",
    "MAX_TIMESTEP = 7 * 288\n",
    "\n",
    "LINES = ['0_1_0', '0_2_1', '10_11_2', '69_70_3', '23_71_4', '70_71_5',\n",
    "       '70_72_6', '69_73_7', '69_74_8', '68_74_9', '73_74_10', '75_76_11',\n",
    "       '68_76_12', '1_11_13', '74_76_14', '76_77_15', '77_78_16',\n",
    "       '76_79_17', '76_79_18', '78_79_19', '76_81_20', '81_82_21',\n",
    "       '82_83_22', '82_84_23', '2_11_24', '83_84_25', '84_85_26',\n",
    "       '84_87_27', '84_88_28', '87_88_29', '88_89_30', '88_89_31',\n",
    "       '89_90_32', '88_91_33', '88_91_34', '6_11_35', '90_91_36',\n",
    "       '91_92_37', '91_93_38', '92_93_39', '93_94_40', '79_95_41',\n",
    "       '81_95_42', '93_95_43', '79_96_44', '79_97_45', '10_12_46',\n",
    "       '79_98_47', '91_99_48', '93_99_49', '94_95_50', '95_96_51',\n",
    "       '97_99_52', '98_99_53', '99_100_54', '91_101_55', '100_101_56',\n",
    "       '11_13_57', '99_102_58', '99_103_59', '102_103_60', '102_104_61',\n",
    "       '99_105_62', '103_104_63', '104_105_64', '104_106_65',\n",
    "       '104_107_66', '105_106_67', '12_14_68', '107_108_69', '102_109_70',\n",
    "       '108_109_71', '109_110_72', '109_111_73', '16_112_74', '31_112_75',\n",
    "       '31_113_76', '26_114_77', '113_114_78', '13_14_79', '11_116_80',\n",
    "       '74_117_81', '75_117_82', '11_15_83', '14_16_84', '3_4_85',\n",
    "       '15_16_86', '16_17_87', '17_18_88', '18_19_89', '14_18_90',\n",
    "       '19_20_91', '20_21_92', '21_22_93', '22_23_94', '22_24_95',\n",
    "       '2_4_96', '24_26_97', '26_27_98', '27_28_99', '7_29_100',\n",
    "       '25_29_101', '16_30_102', '28_30_103', '22_31_104', '30_31_105',\n",
    "       '26_31_106', '4_5_107', '14_32_108', '18_33_109', '34_35_110',\n",
    "       '34_36_111', '32_36_112', '33_35_113', '33_36_114', '36_38_115',\n",
    "       '36_39_116', '29_37_117', '5_6_118', '38_39_119', '39_40_120',\n",
    "       '39_41_121', '40_41_122', '42_43_123', '33_42_124', '43_44_125',\n",
    "       '44_45_126', '45_46_127', '45_47_128', '7_8_129', '46_48_130',\n",
    "       '41_48_131', '41_48_132', '44_48_133', '47_48_134', '48_49_135',\n",
    "       '48_50_136', '50_51_137', '51_52_138', '52_53_139', '8_9_140',\n",
    "       '48_53_141', '48_53_142', '53_54_143', '53_55_144', '54_55_145',\n",
    "       '55_56_146', '49_56_147', '55_57_148', '50_57_149', '53_58_150',\n",
    "       '3_10_151', '55_58_152', '55_58_153', '54_58_154', '58_59_155',\n",
    "       '58_60_156', '59_60_157', '59_61_158', '60_61_159', '62_63_160',\n",
    "       '37_64_161', '4_10_162', '63_64_163', '48_65_164', '48_65_165',\n",
    "       '61_65_166', '61_66_167', '65_66_168', '46_68_169', '48_68_170',\n",
    "       '68_69_171', '23_69_172', '7_4_173', '25_24_174', '80_79_175',\n",
    "       '86_85_176', '115_67_177', '29_16_178', '37_36_179', '62_58_180',\n",
    "       '63_60_181', '64_65_182', '64_67_183', '67_68_184', '80_67_185']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eight-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator(object):\n",
    "    def __init__(self, env, agent, opponent):\n",
    "        self.env = env\n",
    "        self.agent = agent\n",
    "        self.opponent = opponent\n",
    "\n",
    "    def run(self, opponent, num_episodes):\n",
    "        steps_buffer = []\n",
    "        rewards_buffer = []\n",
    "\n",
    "        for i_episode in range(num_episodes):\n",
    "            _ = self.env.reset()\n",
    "            if opponent:\n",
    "                opponent.reset()\n",
    "            max_day = (\n",
    "                self.env.chronics_handler.max_timestep() - MAX_TIMESTEP) // 288\n",
    "            start_timestep = np.random.randint(\n",
    "                max_day) * 288 - 1  # start at 00:00\n",
    "            if start_timestep > 0:\n",
    "                self.env.fast_forward_chronics(start_timestep)\n",
    "\n",
    "            obs = self.env.get_obs()\n",
    "            done = False\n",
    "            steps = 0\n",
    "            rewards = 0\n",
    "            while not done:\n",
    "                action = self.agent.act(obs, None, None)\n",
    "                obs, reward, done, info = self.env.step(action)\n",
    "                assert not info['is_illegal'] and not info['is_ambiguous']\n",
    "                rewards += reward\n",
    "                steps += 1\n",
    "                \n",
    "                if done: # to prevent opponent from taking action on finished episode\n",
    "                    break\n",
    "                \n",
    "                if opponent:\n",
    "                    opponent.take_step(obs)\n",
    "                    if opponent.remaining_time >= 0:\n",
    "                        obs.time_before_cooldown_line[opponent.attack_line] = opponent.remaining_time\n",
    "                        opponent.remaining_time -= 1\n",
    "                    else: # attack (only one disconnection at a time)\n",
    "                        response = opponent.attack(obs)\n",
    "                        if response is not None:\n",
    "                            attack, a = response\n",
    "                            obs, opp_reward, done, info = env.step(attack)\n",
    "                            opponent.tell_attack_continues()\n",
    "                \n",
    "                if steps >= MAX_TIMESTEP:\n",
    "                    break\n",
    "            steps_buffer.append(steps)\n",
    "            rewards_buffer.append(rewards)\n",
    "            print(f'Episode {i_episode+1}/{num_episodes} - Reward: {rewards:.2f}, Num Steps: {steps}')\n",
    "\n",
    "        return np.mean(steps_buffer), np.mean(rewards_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "approved-fleece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05-10 16:52:35 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n",
      "\u001b[32m[05-10 16:52:36 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n",
      "Episode 1/10 - Reward: 351162.17, Num Steps: 417\n",
      "Episode 2/10 - Reward: 166375.65, Num Steps: 180\n",
      "Episode 3/10 - Reward: 148595.93, Num Steps: 138\n",
      "Episode 4/10 - Reward: 194240.34, Num Steps: 171\n",
      "Episode 5/10 - Reward: 11821.87, Num Steps: 14\n",
      "Episode 6/10 - Reward: 106705.63, Num Steps: 111\n",
      "Episode 7/10 - Reward: 44174.30, Num Steps: 46\n",
      "Episode 8/10 - Reward: 351346.66, Num Steps: 356\n",
      "Episode 9/10 - Reward: 287676.35, Num Steps: 257\n",
      "Episode 10/10 - Reward: 31226.88, Num Steps: 35\n",
      "num_episodes: 10, mean_reward: 169332.6, mean_steps: 172.5\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "env_dir=None\n",
    "# how frequent the attack is.\n",
    "# after each attack, next_attack_time is set to 1 + rnadint(attack_period\n",
    "attack_period = 20\n",
    "# how long the line is cooled down for after attack\n",
    "attack_duration = 10\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "backend = LightSimBackend()\n",
    "env = grid2op.make(\"l2rpn_neurips_2020_track2_small\", backend=backend)\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "agent = Track2PowerNetAgent(env.action_space)\n",
    "opponent = RandomOpponent(env.observation_space, env.action_space,\n",
    "                          lines_to_attack=LINES, attack_period=attack_period,\n",
    "                          attack_duration=attack_duration)\n",
    "evaluator = Evaluator(env, agent, opponent)\n",
    "\n",
    "\n",
    "mean_steps, mean_rewards = evaluator.run(opponent, num_episodes)\n",
    "print('num_episodes: {}, mean_reward: {:.1f}, mean_steps: {:.1f}'.format(\n",
    "    num_episodes, mean_rewards, mean_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "domestic-louisiana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[05-10 16:56:59 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n",
      "\u001b[32m[05-10 16:56:59 MainThread @machine_info.py:91]\u001b[0m Cannot find available GPU devices, using CPU or other devices now.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'DoNothingOpponent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ece130b5c6c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrack2PowerNetAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mopponent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoNothingOpponent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DoNothingOpponent' is not defined"
     ]
    }
   ],
   "source": [
    "num_episodes = 10\n",
    "env_dir=None\n",
    "# how frequent the attack is.\n",
    "# after each attack, next_attack_time is set to 1 + rnadint(attack_period\n",
    "attack_period = 20\n",
    "# how long the line is cooled down for after attack\n",
    "attack_duration = 10\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "backend = LightSimBackend()\n",
    "env = grid2op.make(\"l2rpn_neurips_2020_track2_small\", backend=backend)\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "agent = Track2PowerNetAgent(env.action_space)\n",
    "opponent = DoNothingOpponent(env.observation_space, env.action_space)\n",
    "evaluator = Evaluator(env, agent, opponent)\n",
    "\n",
    "mean_steps, mean_rewards = evaluator.run(opponent, num_episodes)\n",
    "print('num_episodes: {}, mean_reward: {:.1f}, mean_steps: {:.1f}'.format(\n",
    "    num_episodes, mean_rewards, mean_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.action_space.name_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-tragedy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
