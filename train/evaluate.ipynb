{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unavailable-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import grid2op\n",
    "from grid2op import make\n",
    "from grid2op.Runner import Runner\n",
    "from grid2op.Reward import L2RPNSandBoxScore, L2RPNReward\n",
    "\n",
    "from kaist_agent.Kaist import Kaist\n",
    "\n",
    "from simple_opponents.random_opponent import RandomOpponent, WeightedRandomOpponent\n",
    "from d3qn.adversary import D3QN_Opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "consistent-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(env, agent, opponent, n_episodes, max_steps, verbose=False):\n",
    "    reward_arr, n_survive_steps_arr = [], []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        step = 0\n",
    "        obs = env.reset()\n",
    "        agent.reset(obs)\n",
    "        if opponent:\n",
    "            opponent.reset(obs)\n",
    "        total_reward = 0\n",
    "        while step < max_steps:\n",
    "            # agent act\n",
    "            a = agent.act(obs, None, None)\n",
    "            obs, reward, done, info = env.step(a)\n",
    "            \n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "            # opponent attack\n",
    "            if opponent:\n",
    "                if opponent.remaining_time >= 0:\n",
    "                    obs.time_before_cooldown_line[opponent.attack_line] = opponent.remaining_time\n",
    "                    opponent.remaining_time -= 1\n",
    "                    opponent.skip_attack(obs)\n",
    "                else:\n",
    "                    response = opponent.attack(obs)\n",
    "                    if response is not None:\n",
    "                        attack, a = response\n",
    "                        obs, opp_reward, done, info = env.step(attack)\n",
    "                        opponent.tell_attack_continues(None, None, None, None)\n",
    "                    \n",
    "            if done:\n",
    "                break\n",
    "            step += 1            \n",
    "            \n",
    "        reward_arr.append(total_reward)\n",
    "        n_survive_steps_arr.append(step)\n",
    "        \n",
    "    if verbose:\n",
    "        for i in range(1, n_episodes+1):\n",
    "            print(f'Episode {i}/{n_episodes} - Reward: {reward_arr[i-1]:.2f}\\t Number of steps survived: {n_survive_steps_arr[i-1]}')\n",
    "        \n",
    "    return reward_arr, n_survive_steps_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-lexington",
   "metadata": {},
   "source": [
    "### Evaluate with no opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "marked-poultry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: 72 S: 128 A: 108 (19)\n",
      "Episode 1/20 - Reward: 53077.66\t Number of steps survived: 150\n",
      "Episode 2/20 - Reward: 43475.25\t Number of steps survived: 150\n",
      "Episode 3/20 - Reward: 50524.64\t Number of steps survived: 150\n",
      "Episode 4/20 - Reward: 55378.95\t Number of steps survived: 150\n",
      "Episode 5/20 - Reward: 44330.47\t Number of steps survived: 150\n",
      "Episode 6/20 - Reward: 50290.00\t Number of steps survived: 150\n",
      "Episode 7/20 - Reward: 62669.68\t Number of steps survived: 150\n",
      "Episode 8/20 - Reward: 53732.96\t Number of steps survived: 150\n",
      "Episode 9/20 - Reward: 49542.81\t Number of steps survived: 150\n",
      "Episode 10/20 - Reward: 47788.03\t Number of steps survived: 150\n",
      "Episode 11/20 - Reward: 53296.05\t Number of steps survived: 150\n",
      "Episode 12/20 - Reward: 44505.76\t Number of steps survived: 150\n",
      "Episode 13/20 - Reward: 45917.02\t Number of steps survived: 150\n",
      "Episode 14/20 - Reward: 44120.46\t Number of steps survived: 150\n",
      "Episode 15/20 - Reward: 51244.66\t Number of steps survived: 150\n",
      "Episode 16/20 - Reward: 45188.34\t Number of steps survived: 150\n",
      "Episode 17/20 - Reward: 53637.30\t Number of steps survived: 150\n",
      "Episode 18/20 - Reward: 46875.51\t Number of steps survived: 150\n",
      "Episode 19/20 - Reward: 53405.19\t Number of steps survived: 150\n",
      "Episode 20/20 - Reward: 52487.60\t Number of steps survived: 150\n",
      "\n",
      "Average reward: 50074.42\t Average number of steps survived: 150.0\n"
     ]
    }
   ],
   "source": [
    "env_name = 'l2rpn_wcci_2020'\n",
    "env = make(env_name, reward_class=L2RPNSandBoxScore,\n",
    "           other_rewards={\n",
    "               \"reward\": L2RPNReward\n",
    "           })\n",
    "\n",
    "agent_name = \"kaist\"\n",
    "data_dir = os.path.join('kaist_agent/data')\n",
    "with open(os.path.join(data_dir, 'param.json'), 'r', encoding='utf-8') as f:\n",
    "    param = json.load(f)\n",
    "\n",
    "state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_std = state_std.masked_fill(state_std<1e-5, 1.)\n",
    "state_mean[0, sum(env.observation_space.shape[:20]):] = 0\n",
    "state_std[0, sum(env.observation_space.shape[:20]):] = 1\n",
    "agent = Kaist(env, state_mean, state_std, name=agent_name, **param)\n",
    "agent.sim_trial = 0\n",
    "agent.load_model(data_dir)\n",
    "\n",
    "n_episodes = 20\n",
    "n_max_steps = 150\n",
    "\n",
    "reward_arr, n_survive_steps_arr = evaluate(env, agent, None, n_episodes, n_max_steps, verbose=True)\n",
    "print()\n",
    "print('Average reward: {:.2f}\\t Average number of steps survived: {}'.format(np.mean(reward_arr), np.mean(n_survive_steps_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-endorsement",
   "metadata": {},
   "source": [
    "### Evaluate with random opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "angry-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: 72 S: 128 A: 108 (19)\n",
      "Episode 1/20 - Reward: 41048.85\t Number of steps survived: 100\n",
      "Episode 2/20 - Reward: 49615.94\t Number of steps survived: 150\n",
      "Episode 3/20 - Reward: 52418.49\t Number of steps survived: 150\n",
      "Episode 4/20 - Reward: 11846.12\t Number of steps survived: 21\n",
      "Episode 5/20 - Reward: 44652.72\t Number of steps survived: 150\n",
      "Episode 6/20 - Reward: 10040.69\t Number of steps survived: 23\n",
      "Episode 7/20 - Reward: 63276.04\t Number of steps survived: 150\n",
      "Episode 8/20 - Reward: 48217.50\t Number of steps survived: 125\n",
      "Episode 9/20 - Reward: 32036.53\t Number of steps survived: 93\n",
      "Episode 10/20 - Reward: 8407.49\t Number of steps survived: 19\n",
      "Episode 11/20 - Reward: 50140.47\t Number of steps survived: 135\n",
      "Episode 12/20 - Reward: 46000.21\t Number of steps survived: 150\n",
      "Episode 13/20 - Reward: 49232.10\t Number of steps survived: 150\n",
      "Episode 14/20 - Reward: 15681.14\t Number of steps survived: 31\n",
      "Episode 15/20 - Reward: 58623.07\t Number of steps survived: 150\n",
      "Episode 16/20 - Reward: 47650.15\t Number of steps survived: 150\n",
      "Episode 17/20 - Reward: 14548.81\t Number of steps survived: 35\n",
      "Episode 18/20 - Reward: 41761.17\t Number of steps survived: 124\n",
      "Episode 19/20 - Reward: 31390.92\t Number of steps survived: 84\n",
      "Episode 20/20 - Reward: 32270.83\t Number of steps survived: 96\n",
      "\n",
      "Average reward: 37442.96\t Average number of steps survived: 104.3\n"
     ]
    }
   ],
   "source": [
    "env_name = 'l2rpn_wcci_2020'\n",
    "env = make(env_name, reward_class=L2RPNSandBoxScore,\n",
    "           other_rewards={\n",
    "               \"reward\": L2RPNReward\n",
    "           })\n",
    "\n",
    "agent_name = \"kaist\"\n",
    "data_dir = os.path.join('kaist_agent/data')\n",
    "with open(os.path.join(data_dir, 'param.json'), 'r', encoding='utf-8') as f:\n",
    "    param = json.load(f)\n",
    "\n",
    "state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_std = state_std.masked_fill(state_std<1e-5, 1.)\n",
    "state_mean[0, sum(env.observation_space.shape[:20]):] = 0\n",
    "state_std[0, sum(env.observation_space.shape[:20]):] = 1\n",
    "agent = Kaist(env, state_mean, state_std, name=agent_name, **param)\n",
    "agent.sim_trial = 0\n",
    "agent.load_model(data_dir)\n",
    "\n",
    "# opponent hyperparameters\n",
    "attack_period = 20\n",
    "attack_duration = 10\n",
    "\n",
    "lines = ['0_4_2', '10_11_11', '11_12_13', '12_13_14', '12_16_20', \n",
    "            '13_14_15', '13_15_16', '14_16_17', '14_35_53', '15_16_21', \n",
    "            '16_17_22', '16_18_23', '16_21_27', '16_21_28', '16_33_48', \n",
    "            '16_33_49', '16_35_54', '17_24_33', '18_19_24', '18_25_35', \n",
    "            '19_20_25', '1_10_12', '1_3_3', '1_4_4', '20_21_26', \n",
    "            '21_22_29', '21_23_30', '21_26_36', '22_23_31', '22_26_39', \n",
    "            '23_24_32', '23_25_34', '23_26_37', '23_26_38', '26_27_40', \n",
    "            '26_28_41', '26_30_56', '27_28_42', '27_29_43', '28_29_44', \n",
    "            '28_31_57', '29_33_50', '29_34_51', '2_3_0', '2_4_1', \n",
    "            '30_31_45', '31_32_47', '32_33_58', '33_34_52', '4_5_55', \n",
    "            '4_6_5', '4_7_6', '5_32_46', '6_7_7', '7_8_8', \n",
    "            '7_9_9', '8_9_10', '9_16_18', '9_16_19']\n",
    "\n",
    "opponent = RandomOpponent(env.observation_space, env.action_space, lines_attacked=lines,\n",
    "                          attack_period=attack_period, attack_duration=10)\n",
    "# simulation hyperparameters\n",
    "n_episodes = 20\n",
    "n_max_steps = 150\n",
    "\n",
    "reward_arr, n_survive_steps_arr = evaluate(env, agent, opponent, n_episodes, n_max_steps, verbose=True)\n",
    "print()\n",
    "print('Average reward: {:.2f}\\t Average number of steps survived: {}'.format(np.mean(reward_arr), np.mean(n_survive_steps_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-belize",
   "metadata": {},
   "source": [
    "### Evaluate with random weighted opponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "virtual-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: 72 S: 128 A: 108 (19)\n",
      "Episode 1/20 - Reward: 34898.01\t Number of steps survived: 92\n",
      "Episode 2/20 - Reward: 23998.14\t Number of steps survived: 64\n",
      "Episode 3/20 - Reward: 40293.94\t Number of steps survived: 116\n",
      "Episode 4/20 - Reward: 55989.25\t Number of steps survived: 150\n",
      "Episode 5/20 - Reward: 21619.62\t Number of steps survived: 64\n",
      "Episode 6/20 - Reward: 36729.14\t Number of steps survived: 105\n",
      "Episode 7/20 - Reward: 64594.12\t Number of steps survived: 150\n",
      "Episode 8/20 - Reward: 36117.51\t Number of steps survived: 100\n",
      "Episode 9/20 - Reward: 52576.48\t Number of steps survived: 150\n",
      "Episode 10/20 - Reward: 8267.36\t Number of steps survived: 14\n",
      "Episode 11/20 - Reward: 54584.61\t Number of steps survived: 150\n",
      "Episode 12/20 - Reward: 20399.39\t Number of steps survived: 60\n",
      "Episode 13/20 - Reward: 14112.05\t Number of steps survived: 16\n",
      "Episode 14/20 - Reward: 44941.41\t Number of steps survived: 150\n",
      "Episode 15/20 - Reward: 56110.97\t Number of steps survived: 148\n",
      "Episode 16/20 - Reward: 8135.84\t Number of steps survived: 18\n",
      "Episode 17/20 - Reward: 54404.19\t Number of steps survived: 150\n",
      "Episode 18/20 - Reward: 48914.14\t Number of steps survived: 150\n",
      "Episode 19/20 - Reward: 15868.05\t Number of steps survived: 38\n",
      "Episode 20/20 - Reward: 55156.31\t Number of steps survived: 150\n",
      "\n",
      "Average reward: 37385.53\t Average number of steps survived: 101.75\n"
     ]
    }
   ],
   "source": [
    "env_name = 'l2rpn_wcci_2020'\n",
    "env = make(env_name, reward_class=L2RPNSandBoxScore,\n",
    "           other_rewards={\n",
    "               \"reward\": L2RPNReward\n",
    "           })\n",
    "\n",
    "agent_name = \"kaist\"\n",
    "data_dir = os.path.join('kaist_agent/data')\n",
    "with open(os.path.join(data_dir, 'param.json'), 'r', encoding='utf-8') as f:\n",
    "    param = json.load(f)\n",
    "\n",
    "state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_std = state_std.masked_fill(state_std<1e-5, 1.)\n",
    "state_mean[0, sum(env.observation_space.shape[:20]):] = 0\n",
    "state_std[0, sum(env.observation_space.shape[:20]):] = 1\n",
    "agent = Kaist(env, state_mean, state_std, name=agent_name, **param)\n",
    "agent.sim_trial = 0\n",
    "agent.load_model(data_dir)\n",
    "\n",
    "# opponent hyperparameters\n",
    "attack_period = 20\n",
    "attack_duration = 10\n",
    "\n",
    "lines = ['0_4_2', '10_11_11', '11_12_13', '12_13_14', '12_16_20', \n",
    "            '13_14_15', '13_15_16', '14_16_17', '14_35_53', '15_16_21', \n",
    "            '16_17_22', '16_18_23', '16_21_27', '16_21_28', '16_33_48', \n",
    "            '16_33_49', '16_35_54', '17_24_33', '18_19_24', '18_25_35', \n",
    "            '19_20_25', '1_10_12', '1_3_3', '1_4_4', '20_21_26', \n",
    "            '21_22_29', '21_23_30', '21_26_36', '22_23_31', '22_26_39', \n",
    "            '23_24_32', '23_25_34', '23_26_37', '23_26_38', '26_27_40', \n",
    "            '26_28_41', '26_30_56', '27_28_42', '27_29_43', '28_29_44', \n",
    "            '28_31_57', '29_33_50', '29_34_51', '2_3_0', '2_4_1', \n",
    "            '30_31_45', '31_32_47', '32_33_58', '33_34_52', '4_5_55', \n",
    "            '4_6_5', '4_7_6', '5_32_46', '6_7_7', '7_8_8', \n",
    "            '7_9_9', '8_9_10', '9_16_18', '9_16_19']\n",
    "\n",
    "opponent = WeightedRandomOpponent(env.observation_space, env.action_space, lines_attacked=lines,\n",
    "                                  attack_period=attack_period, attack_duration=10)\n",
    "# simulation hyperparameters\n",
    "n_episodes = 20\n",
    "n_max_steps = 150\n",
    "\n",
    "reward_arr, n_survive_steps_arr = evaluate(env, agent, opponent, n_episodes, n_max_steps, verbose=True)\n",
    "print()\n",
    "print('Average reward: {:.2f}\\t Average number of steps survived: {}'.format(np.mean(reward_arr), np.mean(n_survive_steps_arr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-television",
   "metadata": {},
   "source": [
    "### Evaluate with untrained D3QN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "national-reporter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: 72 S: 128 A: 108 (19)\n",
      "['2_3_0' '2_4_1' '0_4_2' '1_3_3' '1_4_4' '4_6_5' '4_7_6' '6_7_7' '7_8_8'\n",
      " '7_9_9' '8_9_10' '10_11_11' '1_10_12' '11_12_13' '12_13_14' '13_14_15'\n",
      " '13_15_16' '14_16_17' '9_16_18' '9_16_19' '12_16_20' '15_16_21'\n",
      " '16_17_22' '16_18_23' '18_19_24' '19_20_25' '20_21_26' '16_21_27'\n",
      " '16_21_28' '21_22_29' '21_23_30' '22_23_31' '23_24_32' '17_24_33'\n",
      " '23_25_34' '18_25_35' '21_26_36' '23_26_37' '23_26_38' '22_26_39'\n",
      " '26_27_40' '26_28_41' '27_28_42' '27_29_43' '28_29_44' '30_31_45'\n",
      " '5_32_46' '31_32_47' '16_33_48' '16_33_49' '29_33_50' '29_34_51'\n",
      " '33_34_52' '14_35_53' '16_35_54' '4_5_55' '26_30_56' '28_31_57'\n",
      " '32_33_58']\n",
      "Episode 1/20 - Reward: 48441.76\t Number of steps survived: 150\n",
      "Episode 2/20 - Reward: 42313.91\t Number of steps survived: 150\n",
      "Episode 3/20 - Reward: 47742.77\t Number of steps survived: 150\n",
      "Episode 4/20 - Reward: 50194.99\t Number of steps survived: 150\n",
      "Episode 5/20 - Reward: 39644.38\t Number of steps survived: 150\n",
      "Episode 6/20 - Reward: 46314.69\t Number of steps survived: 150\n",
      "Episode 7/20 - Reward: 53581.43\t Number of steps survived: 150\n",
      "Episode 8/20 - Reward: 52036.05\t Number of steps survived: 150\n",
      "Episode 9/20 - Reward: 44451.63\t Number of steps survived: 150\n",
      "Episode 10/20 - Reward: 42499.51\t Number of steps survived: 150\n",
      "Episode 11/20 - Reward: 48511.46\t Number of steps survived: 150\n",
      "Episode 12/20 - Reward: 41026.26\t Number of steps survived: 150\n",
      "Episode 13/20 - Reward: 43711.99\t Number of steps survived: 150\n",
      "Episode 14/20 - Reward: 41644.71\t Number of steps survived: 150\n",
      "Episode 15/20 - Reward: 47284.08\t Number of steps survived: 150\n",
      "Episode 16/20 - Reward: 41256.53\t Number of steps survived: 150\n",
      "Episode 17/20 - Reward: 47041.66\t Number of steps survived: 150\n",
      "Episode 18/20 - Reward: 42912.97\t Number of steps survived: 150\n",
      "Episode 19/20 - Reward: 48973.30\t Number of steps survived: 150\n",
      "Episode 20/20 - Reward: 49399.61\t Number of steps survived: 150\n",
      "\n",
      "Average reward: 45949.18\t Average number of steps survived: 150.0\n"
     ]
    }
   ],
   "source": [
    "env_name = 'l2rpn_wcci_2020'\n",
    "env = make(env_name, reward_class=L2RPNSandBoxScore,\n",
    "           other_rewards={\n",
    "               \"reward\": L2RPNReward\n",
    "           })\n",
    "\n",
    "agent_name = \"kaist\"\n",
    "data_dir = os.path.join('kaist_agent/data')\n",
    "with open(os.path.join(data_dir, 'param.json'), 'r', encoding='utf-8') as f:\n",
    "    param = json.load(f)\n",
    "\n",
    "state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_std = state_std.masked_fill(state_std<1e-5, 1.)\n",
    "state_mean[0, sum(env.observation_space.shape[:20]):] = 0\n",
    "state_std[0, sum(env.observation_space.shape[:20]):] = 1\n",
    "agent = Kaist(env, state_mean, state_std, name=agent_name, **param)\n",
    "agent.sim_trial = 0\n",
    "agent.load_model(data_dir)\n",
    "\n",
    "# opponent hyperparameters\n",
    "attack_period = 20\n",
    "attack_duration = 10\n",
    "\n",
    "lines = ['0_4_2', '10_11_11', '11_12_13', '12_13_14', '12_16_20', \n",
    "            '13_14_15', '13_15_16', '14_16_17', '14_35_53', '15_16_21', \n",
    "            '16_17_22', '16_18_23', '16_21_27', '16_21_28', '16_33_48', \n",
    "            '16_33_49', '16_35_54', '17_24_33', '18_19_24', '18_25_35', \n",
    "            '19_20_25', '1_10_12', '1_3_3', '1_4_4', '20_21_26', \n",
    "            '21_22_29', '21_23_30', '21_26_36', '22_23_31', '22_26_39', \n",
    "            '23_24_32', '23_25_34', '23_26_37', '23_26_38', '26_27_40', \n",
    "            '26_28_41', '26_30_56', '27_28_42', '27_29_43', '28_29_44', \n",
    "            '28_31_57', '29_33_50', '29_34_51', '2_3_0', '2_4_1', \n",
    "            '30_31_45', '31_32_47', '32_33_58', '33_34_52', '4_5_55', \n",
    "            '4_6_5', '4_7_6', '5_32_46', '6_7_7', '7_8_8', \n",
    "            '7_9_9', '8_9_10', '9_16_18', '9_16_19']\n",
    "\n",
    "opponent = D3QN_Opponent(env.action_space, env.observation_space, lines_attacked=lines, attack_period=attack_period,\n",
    "                attack_duration=attack_duration,is_training=False)\n",
    "\n",
    "# simulation hyperparameters\n",
    "n_episodes = 20\n",
    "n_max_steps = 150\n",
    "\n",
    "reward_arr, n_survive_steps_arr = evaluate(env, agent, opponent, n_episodes, n_max_steps, verbose=True)\n",
    "print()\n",
    "print('Average reward: {:.2f}\\t Average number of steps survived: {}'.format(np.mean(reward_arr), np.mean(n_survive_steps_arr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-chapel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
