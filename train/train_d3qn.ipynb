{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "interested-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "import grid2op\n",
    "from d3qn.adversary import D3QN_Opponent\n",
    "from grid2op.Agent import DoNothingAgent\n",
    "from grid2op.Action import TopologyChangeAndDispatchAction\n",
    "from grid2op.Reward import CombinedScaledReward, L2RPNSandBoxScore, L2RPNReward, GameplayReward\n",
    "from l2rpn_baselines.DoubleDuelingDQN.DoubleDuelingDQNConfig import DoubleDuelingDQNConfig as cfg\n",
    "\n",
    "from kaist_agent.Kaist import Kaist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forced-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TIMESTEP = 7 * 288\n",
    "\n",
    "def train_adversary(env, agent, opponent, num_pre_training_steps, n_iter, save_path, log_path):\n",
    "    # Make sure we can fill the experience buffer\n",
    "    if num_pre_training_steps < opponent.batch_size * opponent.num_frames:\n",
    "        num_pre_training_steps = opponent.batch_size * opponent.num_frames\n",
    "        \n",
    "    # Loop vars\n",
    "    num_training_steps = n_iter\n",
    "    num_steps = num_pre_training_steps + num_training_steps\n",
    "    step = 0\n",
    "    alive_steps = 0\n",
    "    total_reward = 0\n",
    "    done = True\n",
    "    print(f\"Total number of steps: {num_steps}\")\n",
    "\n",
    "    # Create file system related vars\n",
    "    logpath = os.path.join(log_path, opponent.name)\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    modelpath = os.path.join(save_path, opponent.name + \".h5\")\n",
    "    opponent.tf_writer = tf.summary.create_file_writer(logpath, name=opponent.name)\n",
    "    opponent._save_hyperparameters(save_path, env, num_steps)\n",
    "    \n",
    "    while step < num_steps:\n",
    "        # Init first time or new episode\n",
    "        if done:\n",
    "            new_obs = env.reset() # This shouldn't raise\n",
    "            agent.reset(new_obs)\n",
    "            opponent.reset(new_obs)\n",
    "        if cfg.VERBOSE and step % 1000 == 0:\n",
    "            print(\"Step [{}] -- Random [{}]\".format(step, opponent.epsilon))\n",
    "\n",
    "        # Save current observation to stacking buffer\n",
    "        opponent._save_current_frame(opponent.state)\n",
    "\n",
    "        # Execute attack if allowed\n",
    "        if step <= num_pre_training_steps:\n",
    "            opponent.remaining_time = 0\n",
    "            attack, a = opponent._do_nothing, 0\n",
    "        else:\n",
    "            attack, a = opponent.attack(new_obs)\n",
    "\n",
    "        if a != 0:\n",
    "            print(f'ATTACK step {step}: disconnected {a}')\n",
    "            attack_obs, opp_reward, done, info = env.step(attack)\n",
    "            if info[\"is_illegal\"] or info[\"is_ambiguous\"] or \\\n",
    "               info[\"is_dispatching_illegal\"] or info[\"is_illegal_reco\"]:\n",
    "                if cfg.VERBOSE:\n",
    "                    print(attack, info)\n",
    "            new_obs = attack_obs\n",
    "            opponent.tell_attack_continues(None, None, None, None)\n",
    "\n",
    "        while opponent.remaining_time >= 0:\n",
    "            new_obs.time_before_cooldown_line[opponent.attack_line] = opponent.remaining_time\n",
    "            response = agent.act(new_obs, None, None)\n",
    "            new_obs, reward, done, info = env.step(response)\n",
    "            opponent.remaining_time -= 1\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Save new observation to stacking buffer\n",
    "        new_state = opponent.convert_obs(new_obs)\n",
    "        opponent._save_next_frame(new_state)\n",
    "\n",
    "        # Save to experience buffer\n",
    "        if len(opponent.frames2) == opponent.num_frames:\n",
    "            opponent.per_buffer.add(np.array(opponent.frames),\n",
    "                                a, -1 * reward,\n",
    "                                np.array(opponent.frames2),\n",
    "                                opponent.done)\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        # Perform training when we have enough experience in buffer\n",
    "        if step >= num_pre_training_steps:\n",
    "            training_step = step - num_pre_training_steps\n",
    "            # Decay chance of random action\n",
    "            opponent.epsilon = opponent._adaptive_epsilon_decay(training_step)\n",
    "\n",
    "            # Perform training at given frequency\n",
    "            if step % cfg.UPDATE_FREQ == 0 and \\\n",
    "               len(opponent.per_buffer) >= opponent.batch_size:\n",
    "                # Perform training\n",
    "                opponent._batch_train(training_step, step)\n",
    "\n",
    "                if cfg.UPDATE_TARGET_SOFT_TAU > 0.0:\n",
    "                    tau = cfg.UPDATE_TARGET_SOFT_TAU\n",
    "                    # Update target network towards primary network\n",
    "                    opponent.policy_net.update_target_soft(opponent.target_net.model, tau)\n",
    "\n",
    "            # Every UPDATE_TARGET_HARD_FREQ trainings, update target completely\n",
    "            if cfg.UPDATE_TARGET_HARD_FREQ > 0 and \\\n",
    "               step % (cfg.UPDATE_FREQ * cfg.UPDATE_TARGET_HARD_FREQ) == 0:\n",
    "                opponent.policy_net.update_target_hard(opponent.target_net.model)\n",
    "        \n",
    "        if done:\n",
    "            opponent.epoch_rewards.append(-1 * total_reward)\n",
    "            opponent.epoch_alive.append(alive_steps)\n",
    "            if cfg.VERBOSE and step > num_pre_training_steps:\n",
    "                print(\"step {}: Survived [{}] steps\".format(step, alive_steps))\n",
    "                print(\"Total reward of agent [{}]\".format(total_reward))\n",
    "            alive_steps = 0\n",
    "            total_reward = 0         \n",
    "        else:\n",
    "            alive_steps += 1\n",
    "            \n",
    "        ######## After Each Step #######\n",
    "        if step > 0 and step % 2000 == 0: # save network every 5000 iters\n",
    "            opponent.save(modelpath)\n",
    "        step += 1\n",
    "        # Make new obs the current obs\n",
    "        opponent.obs = new_obs\n",
    "        opponent.state = new_state\n",
    "\n",
    "    # Save model after all steps\n",
    "    opponent.save(modelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sought-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75438>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75390>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75470>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da754e0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75550>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da755c0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75668>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75710>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75780>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da757f0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75860>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75898>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da758d0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75940>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da759b0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da759e8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75a20>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75a58>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75ac8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75b38>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75ba8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75c50>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75cf8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75d68>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75da0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75dd8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75e48>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75eb8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75ef0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75f28>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75f60>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75fd0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75208>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75358>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da752b0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9da75278>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03860>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03ba8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03cf8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03cc0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03c88>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03c50>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03c18>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03be0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03080>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de030b8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de030f0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03160>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de031d0>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03208>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03240>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03278>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de032e8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03358>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de033c8>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03470>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03518>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de03588>,\n",
       "       <grid2op.Space.GridObjects.TopologyAndDispatchAction_l2rpn_wcci_2020 object at 0x7fbd9de035c0>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opponent._attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "suspended-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'head_number': 8, 'n_history': 12, 'state_dim': 128, 'dropout': 0.0, 'sim_trial': 15, 'threshold': 0.35, 'max_low_len': 19, 'danger': 0.9, 'mask': 3, 'mask_hi': 19, 'use_order': True, 'device': 'cpu'}\n",
      "O: 72 S: 128 A: 108 (19)\n",
      "['2_3_0' '2_4_1' '0_4_2' '1_3_3' '1_4_4' '4_6_5' '4_7_6' '6_7_7' '7_8_8'\n",
      " '7_9_9' '8_9_10' '10_11_11' '1_10_12' '11_12_13' '12_13_14' '13_14_15'\n",
      " '13_15_16' '14_16_17' '9_16_18' '9_16_19' '12_16_20' '15_16_21'\n",
      " '16_17_22' '16_18_23' '18_19_24' '19_20_25' '20_21_26' '16_21_27'\n",
      " '16_21_28' '21_22_29' '21_23_30' '22_23_31' '23_24_32' '17_24_33'\n",
      " '23_25_34' '18_25_35' '21_26_36' '23_26_37' '23_26_38' '22_26_39'\n",
      " '26_27_40' '26_28_41' '27_28_42' '27_29_43' '28_29_44' '30_31_45'\n",
      " '5_32_46' '31_32_47' '16_33_48' '16_33_49' '29_33_50' '29_34_51'\n",
      " '33_34_52' '14_35_53' '16_35_54' '4_5_55' '26_30_56' '28_31_57'\n",
      " '32_33_58']\n",
      "Total number of steps: 10256\n",
      "Step [0] -- Random [0.99]\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "Random move\n",
      "45\n",
      "ATTACK step 257: disconnected 45\n",
      "Random move\n",
      "23\n",
      "ATTACK step 258: disconnected 23\n",
      "step 258: Survived [258] steps\n",
      "Total reward of agent [225.60018587112427]\n",
      "0\n",
      "0\n",
      "0\n",
      "Random move\n",
      "35\n",
      "ATTACK step 262: disconnected 35\n",
      "Random move\n",
      "11\n",
      "ATTACK step 263: disconnected 11\n",
      "Random move\n",
      "49\n",
      "ATTACK step 264: disconnected 49\n",
      "Random move\n",
      "0\n",
      "Random move\n",
      "50\n",
      "ATTACK step 266: disconnected 50\n",
      "Random move\n",
      "6\n",
      "ATTACK step 267: disconnected 6\n",
      "Random move\n",
      "10\n",
      "ATTACK step 268: disconnected 10\n",
      "Random move\n",
      "21\n",
      "ATTACK step 269: disconnected 21\n",
      "Random move\n",
      "7\n",
      "ATTACK step 270: disconnected 7\n",
      "Random move\n",
      "32\n",
      "ATTACK step 271: disconnected 32\n",
      "Random move\n",
      "29\n",
      "ATTACK step 272: disconnected 29\n",
      "Random move\n",
      "38\n",
      "ATTACK step 273: disconnected 38\n",
      "step 273: Survived [14] steps\n",
      "Total reward of agent [10.489551603794098]\n",
      "0\n",
      "0\n",
      "0\n",
      "Random move\n",
      "22\n",
      "ATTACK step 277: disconnected 22\n",
      "step 277: Survived [3] steps\n",
      "Total reward of agent [1.54433274269104]\n",
      "0\n",
      "0\n",
      "0\n",
      "loss = 5975302.5\n",
      "Random move\n",
      "18\n",
      "ATTACK step 281: disconnected 18\n",
      "Random move\n",
      "7\n",
      "ATTACK step 282: disconnected 7\n",
      "Random move\n",
      "24\n",
      "ATTACK step 283: disconnected 24\n"
     ]
    },
    {
     "ename": "Grid2OpException",
     "evalue": "Grid2OpException \"Impossible to make a step with a non initialized backend. Have you called \"env.reset()\" after the last game over ?\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGrid2OpException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2fe13f5ac283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tf_logs_D3QN\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtrain_adversary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_pre_training_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9104b198d971>\u001b[0m in \u001b[0;36mtrain_adversary\u001b[0;34m(env, agent, opponent, num_pre_training_steps, n_iter, save_path, log_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_before_cooldown_line\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_line\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mnew_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m             \u001b[0mopponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_time\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/grid2op/Environment/BaseEnv.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_init\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             raise Grid2OpException(\"Impossible to make a step with a non initialized backend. Have you called \"\n\u001b[0m\u001b[1;32m   1276\u001b[0m                                    \"\\\"env.reset()\\\" after the last game over ?\")\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGrid2OpException\u001b[0m: Grid2OpException \"Impossible to make a step with a non initialized backend. Have you called \"env.reset()\" after the last game over ?\""
     ]
    }
   ],
   "source": [
    "env_name = 'l2rpn_wcci_2020'\n",
    "env = grid2op.make(env_name,\n",
    "#            action_class=TopologyChangeAndDispatchAction,\n",
    "           reward_class=CombinedScaledReward)\n",
    "\n",
    "# Agent \n",
    "agent_name = \"kaist\"\n",
    "data_dir = os.path.join('kaist_agent/data')\n",
    "with open(os.path.join(data_dir, 'param.json'), 'r', encoding='utf-8') as f:\n",
    "    param = json.load(f)\n",
    "print(param)\n",
    "state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_std = state_std.masked_fill(state_std<1e-5, 1.)\n",
    "state_mean[0, sum(env.observation_space.shape[:20]):] = 0\n",
    "state_std[0, sum(env.observation_space.shape[:20]):] = 1\n",
    "agent = Kaist(env, state_mean, state_std, name=agent_name, **param)\n",
    "agent.sim_trial = 0\n",
    "agent.load_model(data_dir)\n",
    "\n",
    "# Opponent \n",
    "opponent_name = \"D3QN_kaist\"\n",
    "num_pre_training_steps = 256\n",
    "learning_rate = 1e-4\n",
    "initial_epsilon = 0.99\n",
    "final_epsilon = 0.01\n",
    "decay_epsilon = 10000\n",
    "attack_period = 20\n",
    "lines = ['0_4_2', '10_11_11', '11_12_13', '12_13_14', '12_16_20', \n",
    "            '13_14_15', '13_15_16', '14_16_17', '14_35_53', '15_16_21', \n",
    "            '16_17_22', '16_18_23', '16_21_27', '16_21_28', '16_33_48', \n",
    "            '16_33_49', '16_35_54', '17_24_33', '18_19_24', '18_25_35', \n",
    "            '19_20_25', '1_10_12', '1_3_3', '1_4_4', '20_21_26', \n",
    "            '21_22_29', '21_23_30', '21_26_36', '22_23_31', '22_26_39', \n",
    "            '23_24_32', '23_25_34', '23_26_37', '23_26_38', '26_27_40', \n",
    "            '26_28_41', '26_30_56', '27_28_42', '27_29_43', '28_29_44', \n",
    "            '28_31_57', '29_33_50', '29_34_51', '2_3_0', '2_4_1', \n",
    "            '30_31_45', '31_32_47', '32_33_58', '33_34_52', '4_5_55', \n",
    "            '4_6_5', '4_7_6', '5_32_46', '6_7_7', '7_8_8', \n",
    "            '7_9_9', '8_9_10', '9_16_18', '9_16_19']\n",
    "\n",
    "opponent = D3QN_Opponent(env.action_space, env.observation_space, lines_attacked=lines, attack_period=attack_period,\n",
    "            name=opponent_name, is_training=True, learning_rate=learning_rate,\n",
    "            initial_epsilon=initial_epsilon, final_epsilon=final_epsilon, decay_epsilon=decay_epsilon)\n",
    "\n",
    "# Training\n",
    "n_iter = 10000\n",
    "# Register custom reward for training\n",
    "cr = env._reward_helper.template_reward\n",
    "#cr.addReward(\"overflow\", CloseToOverflowReward(), 1.0)\n",
    "cr.addReward(\"game\", GameplayReward(), 1.0)\n",
    "#cr.addReward(\"recolines\", LinesReconnectedReward(), 1.0)\n",
    "cr.addReward(\"l2rpn\", L2RPNReward(), 2.0/float(env.n_line))\n",
    "# Initialize custom rewards\n",
    "cr.initialize(env)\n",
    "# Set reward range to something managable\n",
    "cr.set_range(-1.0, 1.0)\n",
    "\n",
    "save_path = \"kaist_agent_D3QN_opponent_{}_{}\".format(attack_period, n_iter)\n",
    "log_path=\"tf_logs_D3QN\"\n",
    "\n",
    "train_adversary(env, agent, opponent, num_pre_training_steps, n_iter, save_path, log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-fight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op import make\n",
    "from grid2op.Runner import Runner\n",
    "from grid2op.Reward import L2RPNSandBoxScore, L2RPNReward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-divide",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_episode = 10 # number of episodes to evaluate\n",
    "log_path = './logs-evals'\n",
    "nb_process = 1 # number of cores to use\n",
    "max_iter = 150 # maximum number of steps per scenario\n",
    "verbose = True\n",
    "save_gif = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'l2rpn_wcci_2020'\n",
    "env = make(env_name, reward_class=L2RPNSandBoxScore,\n",
    "           other_rewards={\n",
    "               \"reward\": L2RPNReward\n",
    "           })\n",
    "\n",
    "agent_name = \"kaist\"\n",
    "data_dir = os.path.join('kaist_agent/data')\n",
    "with open(os.path.join(data_dir, 'param.json'), 'r', encoding='utf-8') as f:\n",
    "    param = json.load(f)\n",
    "\n",
    "state_mean = torch.load(os.path.join(data_dir, 'mean.pt'), map_location=param['device']).cpu()\n",
    "state_std = torch.load(os.path.join(data_dir, 'std.pt'), map_location=param['device']).cpu()\n",
    "state_std = state_std.masked_fill(state_std<1e-5, 1.)\n",
    "state_mean[0, sum(env.observation_space.shape[:20]):] = 0\n",
    "state_std[0, sum(env.observation_space.shape[:20]):] = 1\n",
    "agent = Kaist(env, state_mean, state_std, name=agent_name, **param)\n",
    "agent.sim_trial = 0\n",
    "agent.load_model(data_dir)\n",
    "    \n",
    "runner_params = env.get_params_for_runner()\n",
    "runner_params[\"verbose\"] = False\n",
    "runner = Runner(**runner_params, agentClass=None, agentInstance=agent)\n",
    "    \n",
    "res = runner.run(path_save=log_path, nb_episode=nb_episode, nb_process=nb_process, max_iter=150)\n",
    "if verbose:\n",
    "    print(\"Evaluation summary:\")\n",
    "    for _, chron_name, cum_reward, nb_time_step, max_ts in res:\n",
    "        msg_tmp = \"chronics at: {}\".format(chron_name)\n",
    "        msg_tmp += \"\\ttotal reward: {:.6f}\".format(cum_reward)\n",
    "        msg_tmp += \"\\ttime steps: {:.0f}/{:.0f}\".format(nb_time_step,\n",
    "                                                        max_ts)\n",
    "        print(msg_tmp)\n",
    "\n",
    "if save_gif:\n",
    "    save_log_gif(log_path, res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-voluntary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
